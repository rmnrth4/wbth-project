{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "### NLTK Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_columns_in_dataframe(df):\n",
    "#     columns_to_merge = [\n",
    "#         \"pagetitle\",\n",
    "#         \"subtitle\",\n",
    "#         \"introduction\",\n",
    "#         \"summarybox\",\n",
    "#         \"content\",\n",
    "#         \"accordion\",\n",
    "#     ]\n",
    "#     new_df = df.loc[:, [\"url\", \"pagetitle\"]].copy()\n",
    "#     new_df[\"text\"] = df.apply(\n",
    "#         lambda row: \" \".join([str(row[col]) for col in columns_to_merge]), axis=1\n",
    "#     )\n",
    "#     return new_df\n",
    "\n",
    "\n",
    "def merge_columns_in_dataframe(df):\n",
    "    columns_to_merge = [\n",
    "        \"pagetitle\",\n",
    "        \"subtitle\",\n",
    "        \"introduction\",\n",
    "        \"summarybox\",\n",
    "        \"content\",\n",
    "        \"accordion\",\n",
    "    ]\n",
    "    new_df = df.loc[:, [\"url\", \"pagetitle\"]].copy()\n",
    "\n",
    "    # Funktion, die die Inhalte zusammenführt und dabei auf Duplikate zwischen `introduction` und `content` achtet\n",
    "    def merge_row(row):\n",
    "        # Fügen Sie zuerst die Inhalte hinzu, die sich nicht überschneiden\n",
    "        non_overlapping_content = \" \".join([str(row[col]) for col in columns_to_merge if col not in ['introduction', 'content']])\n",
    "        \n",
    "        # Überprüfen, ob der Inhalt von 'introduction' bereits in 'content' enthalten ist\n",
    "        if pd.notna(row['introduction']) and pd.notna(row['content']):\n",
    "            if str(row['introduction']) not in str(row['content']):\n",
    "                combined_content = f\"{str(row['introduction'])} {str(row['content'])}\"\n",
    "            else:\n",
    "                combined_content = str(row['content'])\n",
    "        else:\n",
    "            # Wenn einer der Werte NaN ist, verwenden Sie einfach eine direkte Verkettung mit einem Leerzeichen dazwischen\n",
    "            combined_content = f\"{str(row['introduction'])} {str(row['content'])}\"\n",
    "\n",
    "        # Kombinieren Sie den Inhalt aus 'introduction' und 'content' mit den anderen Spalten\n",
    "        full_text = f\"{non_overlapping_content} {combined_content}\"\n",
    "        return full_text\n",
    "\n",
    "    # Anwenden der `merge_row` Funktion auf jede Zeile\n",
    "    new_df['text'] = df.apply(merge_row, axis=1)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_text_preprocessing(text):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import SnowballStemmer\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens if token not in stopwords.words(\"german\")\n",
    "    ]\n",
    "    stemmer = SnowballStemmer(\"german\")\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    processed_text = \" \".join(stemmed_tokens)\n",
    "    return processed_text\n",
    "\n",
    "def get_sentiment(text_string):\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    scores = analyzer.polarity_scores(text_string)\n",
    "    return pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_cols(dataframe, analysis_method, text_col=\"text\"):\n",
    "    if analysis_method == \"distilbert\":\n",
    "        sentiment_cols = dataframe[text_col].apply(get_sentiment_distilbert)\n",
    "    elif analysis_method == \"nltk\" or analysis_method == \"spacy\":\n",
    "        sentiment_cols = dataframe[text_col].apply(get_sentiment)\n",
    "    else:\n",
    "        \"please provide method (nltk/spacy/distilbert)\"\n",
    "    dataframe = pd.concat([dataframe, sentiment_cols], axis=1)\n",
    "    # dataframe['judgement'] = dataframe['compound'].apply(lambda x: 'positive' if x > 0.05 else (\"negative\" if x < -0.05 else 'neutral'))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_data(json_file, analysis_method):\n",
    "    pandas_df = pd.read_json(json_file)\n",
    "    filtered_df = pandas_df.loc[(pandas_df.loc[:, ~pandas_df.columns.isin(['url', 'pagetitle'])] != \"\").any(axis=1)] # excludes all columns from the analysis that have \"\" in the columns except \"pagetitle\" \n",
    "    data = merge_columns_in_dataframe(filtered_df)\n",
    "    if analysis_method == \"nltk\":\n",
    "        data[\"text\"] = data[\"text\"].apply(nltk_text_preprocessing)\n",
    "    elif analysis_method == \"spacy\":\n",
    "        data[\"text\"] = data[\"text\"].apply(spacy_text_preprocessing)\n",
    "    return add_sentiment_cols(data, analysis_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_text_preprocessing(text):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    doc = nlp(text.lower())\n",
    "    filtered_tokens = [token for token in doc if not token.is_stop] # exclusion of stop words\n",
    "\n",
    "    lemmatized_tokens = [token.lemma_ for token in filtered_tokens]\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface DistillBERT Model Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_scores(sentiment_results):\n",
    "    scores = {'negative': [], 'neutral': [], 'positive': []}\n",
    "    for result in sentiment_results:\n",
    "        for res in result:\n",
    "            scores[res['label']].append(res['score'])\n",
    "    average_scores = {label: sum(score_list) / len(score_list) if score_list else 0 for label, score_list in scores.items()}\n",
    "    return average_scores\n",
    "\n",
    "\n",
    "def get_sentiment_distilbert(text_string):\n",
    "    from transformers import pipeline\n",
    "    import spacy\n",
    "\n",
    "    classifier = pipeline('sentiment-analysis',\n",
    "        model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "        top_k=None,\n",
    "        truncation=False,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        nlp = spacy.load('de_core_news_sm')\n",
    "        doc = nlp(text_string)\n",
    "\n",
    "        tokens = [token.text for token in doc]\n",
    "        results = []\n",
    "        if len(tokens) > 300:\n",
    "            for sentence in doc.sents:\n",
    "                result = classifier(sentence.text)\n",
    "                results.extend(result)\n",
    "        else:\n",
    "            result = classifier(text_string)\n",
    "            results.extend(result)\n",
    "\n",
    "        average_scores = calculate_average_scores(results)\n",
    "        return pd.Series(average_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text_string} with error {e}\")\n",
    "        return pd.Series({'negative': 0, 'neutral': 0, 'positive': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_json(pandas_dataframe, file_name):\n",
    "    import datetime\n",
    "    date_info = datetime.datetime.now().strftime(\"%d-%m-%y\")\n",
    "    pandas_dataframe.to_json(f\"{file_name}_{date_info}.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romanroth/opt/anaconda3/envs/WBTH-Project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "distilbert_results = get_analysis_data(\"../web-crawler/scrapy_mobiliar/mobiscraper/mobiscraper/spiders/scrape_archive/full_scrape_IV.json\", \"distilbert\")\n",
    "save_as_json(distilbert_results, \"saiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_json(pandas_dataframe=distilbert_results, file_name=\"distilbert_s_a_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Distilbert / NLTK / SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>pagetitle</th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Kunst &amp; Nachhaltigkeit Vol. 14: 25 Jahre Prix ...</td>\n",
       "      <td>kunst &amp; nachhalt vol . 14 : 25 jahr prix mobil...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Gebäudeversicherung – der Rundumschutz für Ihr...</td>\n",
       "      <td>gebaudeversicher – rundumschutz haus finanziel...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>E-Autos laden: Was Sie alles wissen müssen</td>\n",
       "      <td>e-autos lad : wiss muss elektroautos vormarsch...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.6767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/medien/me...</td>\n",
       "      <td>Digitale Identität: Mobiliar beteiligt sich an...</td>\n",
       "      <td>digital identitat : mobiliar beteiligt gemeins...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/karriere/...</td>\n",
       "      <td>System Engineering</td>\n",
       "      <td>syst engineering begleit mobiliar weiterentwic...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "1  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3  https://www.mobiliar.ch/die-mobiliar/medien/me...   \n",
       "4  https://www.mobiliar.ch/die-mobiliar/karriere/...   \n",
       "\n",
       "                                           pagetitle  \\\n",
       "0  Kunst & Nachhaltigkeit Vol. 14: 25 Jahre Prix ...   \n",
       "1  Gebäudeversicherung – der Rundumschutz für Ihr...   \n",
       "2         E-Autos laden: Was Sie alles wissen müssen   \n",
       "3  Digitale Identität: Mobiliar beteiligt sich an...   \n",
       "4                                 System Engineering   \n",
       "\n",
       "                                                text    neg    neu    pos  \\\n",
       "0  kunst & nachhalt vol . 14 : 25 jahr prix mobil...  0.000  0.987  0.013   \n",
       "1  gebaudeversicher – rundumschutz haus finanziel...  0.006  0.982  0.012   \n",
       "2  e-autos lad : wiss muss elektroautos vormarsch...  0.014  0.951  0.035   \n",
       "3  digital identitat : mobiliar beteiligt gemeins...  0.000  0.951  0.049   \n",
       "4  syst engineering begleit mobiliar weiterentwic...  0.013  0.970  0.018   \n",
       "\n",
       "   compound  \n",
       "0    0.2263  \n",
       "1    0.2869  \n",
       "2    0.6767  \n",
       "3    0.3818  \n",
       "4    0.5994  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analysis_data(\"example.json\", \"nltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>pagetitle</th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Kunst &amp; Nachhaltigkeit Vol. 14: 25 Jahre Prix ...</td>\n",
       "      <td>Kunst &amp; Nachhaltigkeit vol -- 14 -- 25 prix Mo...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Gebäudeversicherung – der Rundumschutz für Ihr...</td>\n",
       "      <td>Gebäudeversicherung -- Rundumschutz Haus finan...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>E-Autos laden: Was Sie alles wissen müssen</td>\n",
       "      <td>e-autos laden -- wissen Elektroauto Vormarsch ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/medien/me...</td>\n",
       "      <td>Digitale Identität: Mobiliar beteiligt sich an...</td>\n",
       "      <td>digital Identität -- Mobiliar beteiligen gemei...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/karriere/...</td>\n",
       "      <td>System Engineering</td>\n",
       "      <td>System Engineering begleiten Mobiliar Weiteren...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.9531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "1  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3  https://www.mobiliar.ch/die-mobiliar/medien/me...   \n",
       "4  https://www.mobiliar.ch/die-mobiliar/karriere/...   \n",
       "\n",
       "                                           pagetitle  \\\n",
       "0  Kunst & Nachhaltigkeit Vol. 14: 25 Jahre Prix ...   \n",
       "1  Gebäudeversicherung – der Rundumschutz für Ihr...   \n",
       "2         E-Autos laden: Was Sie alles wissen müssen   \n",
       "3  Digitale Identität: Mobiliar beteiligt sich an...   \n",
       "4                                 System Engineering   \n",
       "\n",
       "                                                text    neg    neu    pos  \\\n",
       "0  Kunst & Nachhaltigkeit vol -- 14 -- 25 prix Mo...  0.000  0.989  0.011   \n",
       "1  Gebäudeversicherung -- Rundumschutz Haus finan...  0.005  0.988  0.007   \n",
       "2  e-autos laden -- wissen Elektroauto Vormarsch ...  0.000  0.990  0.010   \n",
       "3  digital Identität -- Mobiliar beteiligen gemei...  0.000  0.958  0.042   \n",
       "4  System Engineering begleiten Mobiliar Weiteren...  0.005  0.967  0.028   \n",
       "\n",
       "   compound  \n",
       "0    0.2263  \n",
       "1    0.0516  \n",
       "2    0.3612  \n",
       "3    0.3818  \n",
       "4    0.9531  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analysis_data(\"example.json\", \"spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>pagetitle</th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Kunst &amp; Nachhaltigkeit Vol. 14: 25 Jahre Prix ...</td>\n",
       "      <td>Kunst &amp; Nachhaltigkeit Vol. 14: 25 Jahre Prix ...</td>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.869048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Gebäudeversicherung – der Rundumschutz für Ihr...</td>\n",
       "      <td>Gebäudeversicherung – der Rundumschutz für Ihr...</td>\n",
       "      <td>0.430694</td>\n",
       "      <td>0.165596</td>\n",
       "      <td>0.403710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>E-Autos laden: Was Sie alles wissen müssen</td>\n",
       "      <td>E-Autos laden: Was Sie alles wissen müssen Ele...</td>\n",
       "      <td>0.346649</td>\n",
       "      <td>0.205312</td>\n",
       "      <td>0.448039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/medien/me...</td>\n",
       "      <td>Digitale Identität: Mobiliar beteiligt sich an...</td>\n",
       "      <td>Digitale Identität: Mobiliar beteiligt sich an...</td>\n",
       "      <td>0.359737</td>\n",
       "      <td>0.110319</td>\n",
       "      <td>0.529944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/karriere/...</td>\n",
       "      <td>System Engineering</td>\n",
       "      <td>System Engineering Begleiten Sie die Mobiliar ...</td>\n",
       "      <td>0.256660</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.607732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "1  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3  https://www.mobiliar.ch/die-mobiliar/medien/me...   \n",
       "4  https://www.mobiliar.ch/die-mobiliar/karriere/...   \n",
       "\n",
       "                                           pagetitle  \\\n",
       "0  Kunst & Nachhaltigkeit Vol. 14: 25 Jahre Prix ...   \n",
       "1  Gebäudeversicherung – der Rundumschutz für Ihr...   \n",
       "2         E-Autos laden: Was Sie alles wissen müssen   \n",
       "3  Digitale Identität: Mobiliar beteiligt sich an...   \n",
       "4                                 System Engineering   \n",
       "\n",
       "                                                text  negative   neutral  \\\n",
       "0  Kunst & Nachhaltigkeit Vol. 14: 25 Jahre Prix ...  0.067596  0.063357   \n",
       "1  Gebäudeversicherung – der Rundumschutz für Ihr...  0.430694  0.165596   \n",
       "2  E-Autos laden: Was Sie alles wissen müssen Ele...  0.346649  0.205312   \n",
       "3  Digitale Identität: Mobiliar beteiligt sich an...  0.359737  0.110319   \n",
       "4  System Engineering Begleiten Sie die Mobiliar ...  0.256660  0.135608   \n",
       "\n",
       "   positive  \n",
       "0  0.869048  \n",
       "1  0.403710  \n",
       "2  0.448039  \n",
       "3  0.529944  \n",
       "4  0.607732  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analysis_data(\"example.json\", \"distilbert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to display the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Der neue «Liebe Mobiliar»-Spot zeigt, dass Schäden zu Hause immer genau dann passieren, wenn man nicht damit rechnet.  Die Mobiliar startet mit dem neusten «Liebe Mobiliar»-Spot ins neue Jahr. Die Familie im Spot hingegen startet in einen nur auf den ersten Blick gewöhnlichen Sonntagmorgen. Denn: Während die Eltern noch gemütlich vor sich hinschlummern, werden sie von Geräuschen geweckt, die definitiv nicht ins Haus gehören. Grund dafür ist ihre Tochter, die ihr Talent als Eiskunstläuferin entdeckt und mit viel Freude auslebt. Und das hinterlässt Spuren. Was immer kommt – wir helfen Ihnen rasch und unkompliziert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Heute war ein wunderschöner Tag. Ich ging in den Wald spazieren und habe die Tiere beobachtet. Ich freue mich dies bald wieder zu tun.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[0;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(\u001b[43minput_text\u001b[49m\u001b[38;5;241m.\u001b[39mlower())\n\u001b[1;32m      3\u001b[0m output_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n\u001b[1;32m      4\u001b[0m output_text\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_text' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text2.lower())\n",
    "output_text = \" \".join(tokens)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neue « liebe mobiliar » -spot zeigt , schäden hause immer genau passieren , rechnet . mobiliar startet neusten « liebe mobiliar » -spot neue jahr . familie spot hingegen startet ersten blick gewöhnlichen sonntagmorgen . : eltern gemütlich hinschlummern , geräuschen geweckt , definitiv haus gehören . grund dafür tochter , talent eiskunstläuferin entdeckt freude auslebt . hinterlässt spuren . immer kommt – helfen rasch unkompliziert .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "filtered_tokens = [\n",
    "        token for token in tokens if token not in stopwords.words(\"german\")\n",
    "    ]\n",
    "output_text = \" \".join(filtered_tokens)\n",
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neu « lieb mobiliar » -spot zeigt , schad haus imm genau passi , rechnet . mobiliar startet neust « lieb mobiliar » -spot neu jahr . famili spot hingeg startet erst blick gewohn sonntagmorg . : elt gemut hinschlumm , gerausch geweckt , definitiv haus gehor . grund dafur tocht , talent eiskunstlauferin entdeckt freud auslebt . hinterlasst spur . imm kommt – helf rasch unkompliziert .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"german\")\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "output_text_nltk = \" \".join(stemmed_tokens)\n",
    "output_text_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg         0.0000\n",
       "neu         0.9460\n",
       "pos         0.0540\n",
       "compound    0.4215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = analyzer.polarity_scores(output_text_nltk)\n",
    "pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- liebe mobiliar»-spot zeigen -- schäden Hause genau passieren -- rechnen --   Mobiliar starten neu -- liebe mobiliar»-spot -- Familie Spot hingegen starten Blick gewöhnlich Sonntagmorg -- -- Eltern gemütlich hinschlummern -- geräuschen wecken -- definitiv Haus gehören -- Grund Tochter -- Talent eiskunstläuferin entdecken Freude ausleben -- Hinterlässt Spur -- -- helfen rasch unkompliziert --'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "doc = nlp(text.lower())\n",
    "filtered_tokens = [token for token in doc if not token.is_stop] # exclusion of stop words\n",
    "\n",
    "lemmatized_tokens = [token.lemma_ for token in filtered_tokens]\n",
    "output_text_spacy = \" \".join(lemmatized_tokens)\n",
    "output_text_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg         0.0000\n",
       "neu         0.9520\n",
       "pos         0.0480\n",
       "compound    0.4215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = analyzer.polarity_scores(output_text_spacy)\n",
    "pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.642108\n",
       "neutral     0.085077\n",
       "positive    0.272815\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_distilbert(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Habe ich nicht umgesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'positive', 'score': 0.49148350954055786}, {'label': 'neutral', 'score': 0.25997069478034973}, {'label': 'negative', 'score': 0.2485458105802536}], [{'label': 'positive', 'score': 0.9740146994590759}, {'label': 'neutral', 'score': 0.015805009752511978}, {'label': 'negative', 'score': 0.01018031220883131}]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m batch \u001b[38;5;241m=\u001b[39m tokenizer(X_train, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[1;32m     23\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "model_name = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "classifier = pipeline(\n",
    "    model=model_name,\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name),\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "X_train = [\"Ich bin Roman und 28 Jahre alt.\", \"Ich liebe dich!\"]\n",
    "res = classifier(X_train)\n",
    "\n",
    "print(res)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=800, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_name(**batch),\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(output.logits, dim=1),\n",
    "    print(predictions)\n",
    "    labels = torch.argmax(predictions, dim=1)\n",
    "    print(labels)\n",
    "\n",
    "\n",
    "# list_list_of_dicts_of_tuples = res\n",
    "# for list_of_dicts_of_tuples in list_list_of_dicts_of_tuples:\n",
    "#     for dicts in list_of_dicts_of_tuples:\n",
    "#         mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "# print(pd.Series(mydict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WBTH-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
