{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/tutorial/text-analytics-beginners-nltk\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "# download nltk corpus (first time only)\n",
    "# nltk.download(\"all\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "# Installiere das SnowballStemmer für die deutsche Sprache\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns are beeing merged togheter here\n",
    "def merge_columns_in_dataframe(df):\n",
    "    columns_to_merge = ['page_title', 'sub_title', 'introduction', 'summary_box', 'content', 'accordion']\n",
    "    new_df = df.loc[:, [\"url\", \"page_title\"]].copy()\n",
    "    new_df['text'] = df.apply(lambda row: ' '.join([str(row[col]) for col in columns_to_merge]), axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens if token not in stopwords.words(\"german\")\n",
    "    ]\n",
    "    stemmer = SnowballStemmer(\"german\") # eventuell anderen stemmer verwenden\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    processed_text = \" \".join(stemmed_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text_string):\n",
    "    scores = analyzer.polarity_scores(text_string)\n",
    "    return pd.Series(scores)\n",
    "\n",
    "def add_sentiment_cols(dataframe, text_col=\"text\"):\n",
    "    sentiment_cols = dataframe[text_col].apply(get_sentiment)\n",
    "    dataframe = pd.concat([dataframe, sentiment_cols], axis=1)\n",
    "    dataframe['judgement'] = dataframe['compound'].apply(lambda x: 'positive' if x > 0.05 else (\"negative\" if x < -0.05 else 'neutral'))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_data(json_file):\n",
    "    pandas_df = pd.read_json(json_file)\n",
    "    filtered_df = pandas_df.loc[(pandas_df.loc[:, ~pandas_df.columns.isin(['url', 'page_title'])] != \"\").any(axis=1)] # exkludiert alle spalten von der Analyse die \"\" in den spalten ausser \"page_title\" haben \n",
    "    data = merge_columns_in_dataframe(filtered_df)\n",
    "    data[\"text\"] = data[\"text\"].apply(preprocess_text)\n",
    "    return add_sentiment_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_json(pandas_dataframe, file_name):\n",
    "    import datetime\n",
    "    date_info = datetime.datetime.now().strftime(\"%d-%m-%y\")\n",
    "    pandas_dataframe.to_json(f\"{file_name}_{date_info}.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_analysis_data(\"ratgeber_pages_part2.json\")\n",
    "# save_as_json(df, \"ratgeber_pages_with_rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = get_analysis_data(\"../web-crawler/scrapy_mobiliar/mobiscraper/mobiscraper/spiders/scrape_archive/full_scrape_2.json\")\n",
    "# save_as_json(df2, \"full_scrape_2_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>page_title</th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Tierversicherung</td>\n",
       "      <td>tierversicher hund katz versich tierversicher ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.2406</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Cyberversicherung</td>\n",
       "      <td>cyberversicher hilf digital alltag bankgeschaf...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.5362</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Wertsachenversicherung</td>\n",
       "      <td>wertsachenversicher versich , bedeutet wertvol...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Die Hausratversicherung</td>\n",
       "      <td>hausratversicher rundum-versicher beweg sach w...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6662</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Mietkautionsversicherung</td>\n",
       "      <td>mietkautionsversicher dank mietkaution spar mi...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.4329</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Die Fahrrad-Kaskoversicherung vermitteln</td>\n",
       "      <td>fahrrad-kaskoversicher vermitteln umfass versi...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3313</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Projekte 2022: Insgesamt 19 weitere Brücken un...</td>\n",
       "      <td>projekt 2022 : insgesamt 19 weit bruck steg fe...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Projekte 2023: Insgesamt 13 weitere Brücken un...</td>\n",
       "      <td>projekt 2023 : insgesamt 13 weit bruck steg fe...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Winter Wanderland</td>\n",
       "      <td>wint wanderland verschneit tal , weit nebelme ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/nachhalti...</td>\n",
       "      <td>Rein in die Wanderschuhe</td>\n",
       "      <td>rein wanderschuh frisch ferienluft haustur ! d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "1     https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2     https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3     https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "4     https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "...                                                 ...   \n",
       "1456  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "1457  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "1458  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "1459  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "1460  https://www.mobiliar.ch/die-mobiliar/nachhalti...   \n",
       "\n",
       "                                             page_title  \\\n",
       "0                                      Tierversicherung   \n",
       "1                                     Cyberversicherung   \n",
       "2                                Wertsachenversicherung   \n",
       "3                               Die Hausratversicherung   \n",
       "4                              Mietkautionsversicherung   \n",
       "...                                                 ...   \n",
       "1456           Die Fahrrad-Kaskoversicherung vermitteln   \n",
       "1457  Projekte 2022: Insgesamt 19 weitere Brücken un...   \n",
       "1458  Projekte 2023: Insgesamt 13 weitere Brücken un...   \n",
       "1459                                  Winter Wanderland   \n",
       "1460                           Rein in die Wanderschuhe   \n",
       "\n",
       "                                                   text    neg    neu    pos  \\\n",
       "0     tierversicher hund katz versich tierversicher ...  0.000  0.994  0.006   \n",
       "1     cyberversicher hilf digital alltag bankgeschaf...  0.028  0.954  0.019   \n",
       "2     wertsachenversicher versich , bedeutet wertvol...  0.000  0.981  0.019   \n",
       "3     hausratversicher rundum-versicher beweg sach w...  0.021  0.979  0.000   \n",
       "4     mietkautionsversicher dank mietkaution spar mi...  0.007  0.976  0.017   \n",
       "...                                                 ...    ...    ...    ...   \n",
       "1456  fahrrad-kaskoversicher vermitteln umfass versi...  0.028  0.972  0.000   \n",
       "1457  projekt 2022 : insgesamt 19 weit bruck steg fe...  0.000  1.000  0.000   \n",
       "1458  projekt 2023 : insgesamt 13 weit bruck steg fe...  0.000  1.000  0.000   \n",
       "1459  wint wanderland verschneit tal , weit nebelme ...  0.000  1.000  0.000   \n",
       "1460  rein wanderschuh frisch ferienluft haustur ! d...  0.000  0.940  0.060   \n",
       "\n",
       "      compound judgement  \n",
       "0       0.2406  positive  \n",
       "1      -0.5362  negative  \n",
       "2       0.6553  positive  \n",
       "3      -0.6662  negative  \n",
       "4       0.4329  positive  \n",
       "...        ...       ...  \n",
       "1456   -0.3313  negative  \n",
       "1457    0.0000   neutral  \n",
       "1458    0.0000   neutral  \n",
       "1459    0.0000   neutral  \n",
       "1460    0.5093  positive  \n",
       "\n",
       "[1461 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.read_json(\"full_scrape_2_analysis_15-03-24_15:40:08.json\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "judgement\n",
       "neutral     726\n",
       "positive    465\n",
       "negative    270\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"judgement\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to display the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_example = [{\"url\": \"https://www.mobiliar.ch/die-mobiliar/ueber-uns/unsere-werbung/werbespots-liebe-mobiliar/liebe-mobiliar-parkett\", \"page_title\": \"Liebe Mobiliar: Parkett\", \"sub_title\": \"\", \"introduction\": \"Der neue «Liebe Mobiliar»-Spot zeigt, dass Schäden zu Hause immer genau dann passieren, wenn man nicht damit rechnet.\", \"summary_box\": \"\", \"content\": \"Die Mobiliar startet mit dem neusten «Liebe Mobiliar»-Spot ins neue Jahr. Die Familie im Spot hingegen startet in einen nur auf den ersten Blick gewöhnlichen Sonntagmorgen. Denn: Während die Eltern noch gemütlich vor sich hinschlummern, werden sie von Geräuschen geweckt, die definitiv nicht ins Haus gehören. Grund dafür ist ihre Tochter, die ihr Talent als Eiskunstläuferin entdeckt und mit viel Freude auslebt. Und das hinterlässt Spuren. Was immer kommt – wir helfen Ihnen rasch und unkompliziert.\", \"accordion\": \"\"},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>page_title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>introduction</th>\n",
       "      <th>summary_box</th>\n",
       "      <th>content</th>\n",
       "      <th>accordion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.mobiliar.ch/die-mobiliar/ueber-uns...</td>\n",
       "      <td>Liebe Mobiliar: Parkett</td>\n",
       "      <td></td>\n",
       "      <td>Der neue «Liebe Mobiliar»-Spot zeigt, dass Sch...</td>\n",
       "      <td></td>\n",
       "      <td>Die Mobiliar startet mit dem neusten «Liebe Mo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url               page_title  \\\n",
       "0  https://www.mobiliar.ch/die-mobiliar/ueber-uns...  Liebe Mobiliar: Parkett   \n",
       "\n",
       "  sub_title                                       introduction summary_box  \\\n",
       "0            Der neue «Liebe Mobiliar»-Spot zeigt, dass Sch...               \n",
       "\n",
       "                                             content accordion  \n",
       "0  Die Mobiliar startet mit dem neusten «Liebe Mo...            "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame(json_file_example)\n",
    "pandas_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Mobiliar: Parkett  Der neue «Liebe Mobiliar»-Spot zeigt, dass Schäden zu Hause immer genau dann passieren, wenn man nicht damit rechnet.  Die Mobiliar startet mit dem neusten «Liebe Mobiliar»-Spot ins neue Jahr. Die Familie im Spot hingegen startet in einen nur auf den ersten Blick gewöhnlichen Sonntagmorgen. Denn: Während die Eltern noch gemütlich vor sich hinschlummern, werden sie von Geräuschen geweckt, die definitiv nicht ins Haus gehören. Grund dafür ist ihre Tochter, die ihr Talent als Eiskunstläuferin entdeckt und mit viel Freude auslebt. Und das hinterlässt Spuren. Was immer kommt – wir helfen Ihnen rasch und unkompliziert. \n"
     ]
    }
   ],
   "source": [
    "merged_text_df = merge_columns_in_dataframe(pandas_dataframe)\n",
    "for i in merged_text_df[\"text\"]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Der neue «Liebe Mobiliar»-Spot zeigt, dass Schäden zu Hause immer genau dann passieren, wenn man nicht damit rechnet.  Die Mobiliar startet mit dem neusten «Liebe Mobiliar»-Spot ins neue Jahr. Die Familie im Spot hingegen startet in einen nur auf den ersten Blick gewöhnlichen Sonntagmorgen. Denn: Während die Eltern noch gemütlich vor sich hinschlummern, werden sie von Geräuschen geweckt, die definitiv nicht ins Haus gehören. Grund dafür ist ihre Tochter, die ihr Talent als Eiskunstläuferin entdeckt und mit viel Freude auslebt. Und das hinterlässt Spuren. Was immer kommt – wir helfen Ihnen rasch und unkompliziert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Fahren fuhren gefahren fuhr die Fahrt er fährt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['der',\n",
       " 'neue',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'zeigt',\n",
       " ',',\n",
       " 'dass',\n",
       " 'schäden',\n",
       " 'zu',\n",
       " 'hause',\n",
       " 'immer',\n",
       " 'genau',\n",
       " 'dann',\n",
       " 'passieren',\n",
       " ',',\n",
       " 'wenn',\n",
       " 'man',\n",
       " 'nicht',\n",
       " 'damit',\n",
       " 'rechnet',\n",
       " '.',\n",
       " 'die',\n",
       " 'mobiliar',\n",
       " 'startet',\n",
       " 'mit',\n",
       " 'dem',\n",
       " 'neusten',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'ins',\n",
       " 'neue',\n",
       " 'jahr',\n",
       " '.',\n",
       " 'die',\n",
       " 'familie',\n",
       " 'im',\n",
       " 'spot',\n",
       " 'hingegen',\n",
       " 'startet',\n",
       " 'in',\n",
       " 'einen',\n",
       " 'nur',\n",
       " 'auf',\n",
       " 'den',\n",
       " 'ersten',\n",
       " 'blick',\n",
       " 'gewöhnlichen',\n",
       " 'sonntagmorgen',\n",
       " '.',\n",
       " 'denn',\n",
       " ':',\n",
       " 'während',\n",
       " 'die',\n",
       " 'eltern',\n",
       " 'noch',\n",
       " 'gemütlich',\n",
       " 'vor',\n",
       " 'sich',\n",
       " 'hinschlummern',\n",
       " ',',\n",
       " 'werden',\n",
       " 'sie',\n",
       " 'von',\n",
       " 'geräuschen',\n",
       " 'geweckt',\n",
       " ',',\n",
       " 'die',\n",
       " 'definitiv',\n",
       " 'nicht',\n",
       " 'ins',\n",
       " 'haus',\n",
       " 'gehören',\n",
       " '.',\n",
       " 'grund',\n",
       " 'dafür',\n",
       " 'ist',\n",
       " 'ihre',\n",
       " 'tochter',\n",
       " ',',\n",
       " 'die',\n",
       " 'ihr',\n",
       " 'talent',\n",
       " 'als',\n",
       " 'eiskunstläuferin',\n",
       " 'entdeckt',\n",
       " 'und',\n",
       " 'mit',\n",
       " 'viel',\n",
       " 'freude',\n",
       " 'auslebt',\n",
       " '.',\n",
       " 'und',\n",
       " 'das',\n",
       " 'hinterlässt',\n",
       " 'spuren',\n",
       " '.',\n",
       " 'was',\n",
       " 'immer',\n",
       " 'kommt',\n",
       " '–',\n",
       " 'wir',\n",
       " 'helfen',\n",
       " 'ihnen',\n",
       " 'rasch',\n",
       " 'und',\n",
       " 'unkompliziert',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(text.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neue',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'zeigt',\n",
       " ',',\n",
       " 'schäden',\n",
       " 'hause',\n",
       " 'immer',\n",
       " 'genau',\n",
       " 'passieren',\n",
       " ',',\n",
       " 'rechnet',\n",
       " '.',\n",
       " 'mobiliar',\n",
       " 'startet',\n",
       " 'neusten',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'neue',\n",
       " 'jahr',\n",
       " '.',\n",
       " 'familie',\n",
       " 'spot',\n",
       " 'hingegen',\n",
       " 'startet',\n",
       " 'ersten',\n",
       " 'blick',\n",
       " 'gewöhnlichen',\n",
       " 'sonntagmorgen',\n",
       " '.',\n",
       " ':',\n",
       " 'eltern',\n",
       " 'gemütlich',\n",
       " 'hinschlummern',\n",
       " ',',\n",
       " 'geräuschen',\n",
       " 'geweckt',\n",
       " ',',\n",
       " 'definitiv',\n",
       " 'haus',\n",
       " 'gehören',\n",
       " '.',\n",
       " 'grund',\n",
       " 'dafür',\n",
       " 'tochter',\n",
       " ',',\n",
       " 'talent',\n",
       " 'eiskunstläuferin',\n",
       " 'entdeckt',\n",
       " 'freude',\n",
       " 'auslebt',\n",
       " '.',\n",
       " 'hinterlässt',\n",
       " 'spuren',\n",
       " '.',\n",
       " 'immer',\n",
       " 'kommt',\n",
       " '–',\n",
       " 'helfen',\n",
       " 'rasch',\n",
       " 'unkompliziert',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens = [\n",
    "        token for token in tokens if token not in stopwords.words(\"german\")\n",
    "    ]\n",
    "filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neu',\n",
       " '«',\n",
       " 'lieb',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'zeigt',\n",
       " ',',\n",
       " 'schad',\n",
       " 'haus',\n",
       " 'imm',\n",
       " 'genau',\n",
       " 'passi',\n",
       " ',',\n",
       " 'rechnet',\n",
       " '.',\n",
       " 'mobiliar',\n",
       " 'startet',\n",
       " 'neust',\n",
       " '«',\n",
       " 'lieb',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'neu',\n",
       " 'jahr',\n",
       " '.',\n",
       " 'famili',\n",
       " 'spot',\n",
       " 'hingeg',\n",
       " 'startet',\n",
       " 'erst',\n",
       " 'blick',\n",
       " 'gewohn',\n",
       " 'sonntagmorg',\n",
       " '.',\n",
       " ':',\n",
       " 'elt',\n",
       " 'gemut',\n",
       " 'hinschlumm',\n",
       " ',',\n",
       " 'gerausch',\n",
       " 'geweckt',\n",
       " ',',\n",
       " 'definitiv',\n",
       " 'haus',\n",
       " 'gehor',\n",
       " '.',\n",
       " 'grund',\n",
       " 'dafur',\n",
       " 'tocht',\n",
       " ',',\n",
       " 'talent',\n",
       " 'eiskunstlauferin',\n",
       " 'entdeckt',\n",
       " 'freud',\n",
       " 'auslebt',\n",
       " '.',\n",
       " 'hinterlasst',\n",
       " 'spur',\n",
       " '.',\n",
       " 'imm',\n",
       " 'kommt',\n",
       " '–',\n",
       " 'helf',\n",
       " 'rasch',\n",
       " 'unkompliziert',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"german\") # eventuell anderen stemmer verwenden\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neue',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'zeigt',\n",
       " ',',\n",
       " 'schäden',\n",
       " 'hause',\n",
       " 'immer',\n",
       " 'genau',\n",
       " 'passieren',\n",
       " ',',\n",
       " 'rechnet',\n",
       " '.',\n",
       " 'mobiliar',\n",
       " 'startet',\n",
       " 'neusten',\n",
       " '«',\n",
       " 'liebe',\n",
       " 'mobiliar',\n",
       " '»',\n",
       " '-spot',\n",
       " 'neue',\n",
       " 'jahr',\n",
       " '.',\n",
       " 'familie',\n",
       " 'spot',\n",
       " 'hingegen',\n",
       " 'startet',\n",
       " 'ersten',\n",
       " 'blick',\n",
       " 'gewöhnlichen',\n",
       " 'sonntagmorgen',\n",
       " '.',\n",
       " ':',\n",
       " 'eltern',\n",
       " 'gemütlich',\n",
       " 'hinschlummern',\n",
       " ',',\n",
       " 'geräuschen',\n",
       " 'geweckt',\n",
       " ',',\n",
       " 'definitiv',\n",
       " 'haus',\n",
       " 'gehören',\n",
       " '.',\n",
       " 'grund',\n",
       " 'dafür',\n",
       " 'tochter',\n",
       " ',',\n",
       " 'talent',\n",
       " 'eiskunstläuferin',\n",
       " 'entdeckt',\n",
       " 'freude',\n",
       " 'auslebt',\n",
       " '.',\n",
       " 'hinterlässt',\n",
       " 'spuren',\n",
       " '.',\n",
       " 'immer',\n",
       " 'kommt',\n",
       " '–',\n",
       " 'helfen',\n",
       " 'rasch',\n",
       " 'unkompliziert',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.stem import SnowballStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['der',\n",
       " 'neu',\n",
       " '--',\n",
       " 'Liebe',\n",
       " 'Mobiliar»-Spot',\n",
       " 'zeigen',\n",
       " '--',\n",
       " 'daß',\n",
       " 'Schaden',\n",
       " 'zu',\n",
       " 'Haus',\n",
       " 'immer',\n",
       " 'genau',\n",
       " 'dann',\n",
       " 'passieren',\n",
       " '--',\n",
       " 'wenn',\n",
       " 'man',\n",
       " 'nicht',\n",
       " 'damit',\n",
       " 'rechnen',\n",
       " '--',\n",
       " ' ',\n",
       " 'der',\n",
       " 'Mobiliar',\n",
       " 'starten',\n",
       " 'mit',\n",
       " 'der',\n",
       " 'neust',\n",
       " '--',\n",
       " 'Liebe',\n",
       " 'Mobiliar»-Spot',\n",
       " 'in',\n",
       " 'neu',\n",
       " 'Jahr',\n",
       " '--',\n",
       " 'der',\n",
       " 'Familie',\n",
       " 'in',\n",
       " 'Spot',\n",
       " 'hingegen',\n",
       " 'starten',\n",
       " 'in',\n",
       " 'ein',\n",
       " 'nur',\n",
       " 'auf',\n",
       " 'der',\n",
       " 'erster',\n",
       " 'Blick',\n",
       " 'gewöhnlich',\n",
       " 'Sonntagmorg',\n",
       " '--',\n",
       " 'denn',\n",
       " '--',\n",
       " 'während',\n",
       " 'der',\n",
       " 'Eltern',\n",
       " 'noch',\n",
       " 'gemütlich',\n",
       " 'vor',\n",
       " 'sich',\n",
       " 'hinschlummern',\n",
       " '--',\n",
       " 'werden',\n",
       " 'sie',\n",
       " 'von',\n",
       " 'Geräusche',\n",
       " 'wecken',\n",
       " '--',\n",
       " 'der',\n",
       " 'definitiv',\n",
       " 'nicht',\n",
       " 'in',\n",
       " 'Haus',\n",
       " 'gehören',\n",
       " '--',\n",
       " 'Grund',\n",
       " 'dafür',\n",
       " 'sein',\n",
       " 'ihr',\n",
       " 'Tochter',\n",
       " '--',\n",
       " 'der',\n",
       " 'ihr',\n",
       " 'Talent',\n",
       " 'als',\n",
       " 'Eiskunstläuferin',\n",
       " 'entdecken',\n",
       " 'und',\n",
       " 'mit',\n",
       " 'viel',\n",
       " 'Freude',\n",
       " 'ausleben',\n",
       " '--',\n",
       " 'und',\n",
       " 'der',\n",
       " 'hinterlässen',\n",
       " 'Spur',\n",
       " '--',\n",
       " 'was',\n",
       " 'immer',\n",
       " 'kommen',\n",
       " '--',\n",
       " 'wir',\n",
       " 'helfen',\n",
       " 'ihnen',\n",
       " 'rasch',\n",
       " 'und',\n",
       " 'unkompliziert',\n",
       " '--']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# Beispieltext\n",
    "# text = \"fahren fuhren gefahren fuhr die Fahrt\"\n",
    "\n",
    "# Verarbeiten des Textes mit SpaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "filtered_tokens = [\n",
    "        token for token in doc if token not in stopwords.words(\"german\")\n",
    "    ]\n",
    "# Lemmatisieren der Tokens\n",
    "lemmatized_tokens = [token.lemma_ for token in filtered_tokens]\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neu « lieb mobiliar » -spot zeigt , schad haus imm genau passi , rechnet . mobiliar startet neust « lieb mobiliar » -spot neu jahr . famili spot hingeg startet erst blick gewohn sonntagmorg . : elt gemut hinschlumm , gerausch geweckt , definitiv haus gehor . grund dafur tocht , talent eiskunstlauferin entdeckt freud auslebt . hinterlasst spur . imm kommt – helf rasch unkompliziert .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemmed_tokens\n",
    "processed_text = \" \".join(stemmed_tokens)\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.946, 'pos': 0.054, 'compound': 0.4215}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neg         0.0000\n",
       "neu         0.9460\n",
       "pos         0.0540\n",
       "compound    0.4215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = analyzer.polarity_scores(processed_text)\n",
    "print(scores)\n",
    "pd.Series(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'negative', 'score': 0.6421080827713013}, {'label': 'positive', 'score': 0.27281466126441956}, {'label': 'neutral', 'score': 0.0850772112607956}], [{'label': 'positive', 'score': 0.49148350954055786}, {'label': 'neutral', 'score': 0.25997069478034973}, {'label': 'negative', 'score': 0.2485458105802536}], [{'label': 'positive', 'score': 0.9740146994590759}, {'label': 'neutral', 'score': 0.015805009752511978}, {'label': 'negative', 'score': 0.01018031220883131}]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m batch \u001b[38;5;241m=\u001b[39m tokenizer(X_train, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[1;32m     22\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\"\n",
    "classifier = pipeline(\n",
    "    model=model_name,\n",
    "    # return_all_scores=True, ist deprecated\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name),\n",
    "    top_k=None # gibt alle scores zurück\n",
    ")\n",
    "\n",
    "X_train = [text, \"Ich bin Roman und 28 Jahre alt.\", \"Ich liebe dich!\"]\n",
    "res = classifier(X_train)\n",
    "\n",
    "print(res)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=800, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_name(**batch),\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(output.logits, dim=1),\n",
    "    print(predictions)\n",
    "    labels = torch.argmax(predictions, dim=1)\n",
    "    print(labels)\n",
    "\n",
    "\n",
    "# list_list_of_dicts_of_tuples = res\n",
    "# for list_of_dicts_of_tuples in list_list_of_dicts_of_tuples:\n",
    "#     for dicts in list_of_dicts_of_tuples:\n",
    "#         mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "# print(pd.Series(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    0.642108\n",
      "positive    0.272815\n",
      "neutral     0.085077\n",
      "dtype: float64\n",
      "\n",
      "negative    0.010180\n",
      "positive    0.974015\n",
      "neutral     0.015805\n",
      "dtype: float64\n",
      "\n",
      "negative    0.248546\n",
      "positive    0.491484\n",
      "neutral     0.259971\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for list_of_dicts_of_tuples in classifier(text):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))\n",
    "print()\n",
    "for list_of_dicts_of_tuples in classifier(\"Ich liebe dich!\"):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))\n",
    "print()\n",
    "for list_of_dicts_of_tuples in classifier(\"Ich bin Roman und 28 Jahre alt.\"):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    0.642108\n",
      "positive    0.272815\n",
      "neutral     0.085077\n",
      "dtype: float64\n",
      "\n",
      "negative    0.010180\n",
      "positive    0.974015\n",
      "neutral     0.015805\n",
      "dtype: float64\n",
      "\n",
      "negative    0.248546\n",
      "positive    0.491484\n",
      "neutral     0.259971\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "    # return_all_scores=True, ist deprecated\n",
    "    top_k=None, # gibt alle scores zurück\n",
    "    # tokenizer=tok\n",
    ")\n",
    "\n",
    "for list_of_dicts_of_tuples in classifier(text):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))\n",
    "print()\n",
    "for list_of_dicts_of_tuples in classifier(\"Ich liebe dich!\"):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))\n",
    "print()\n",
    "for list_of_dicts_of_tuples in classifier(\"Ich bin Roman und 28 Jahre alt.\"):\n",
    "    for dicts in list_of_dicts_of_tuples:\n",
    "        mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "print(pd.Series(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'negative', 'score': 0.6421080827713013},\n",
       "  {'label': 'positive', 'score': 0.27281466126441956},\n",
       "  {'label': 'neutral', 'score': 0.0850772112607956}]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "# distilled_student_sentiment_classifier(text)\n",
    "distilled_student_sentiment_classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment_hf(text_string):\n",
    "    classifier = pipeline(\n",
    "        model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "        # return_all_scores=True, ist deprecated\n",
    "        truncation=True,\n",
    "        top_k=None # gibt alle scores zurück\n",
    "    )\n",
    "    list_list_of_dicts_of_tuples = classifier(text_string)\n",
    "    mydict = {}\n",
    "    for list_of_dicts_of_tuples in list_list_of_dicts_of_tuples:\n",
    "        for dicts in list_of_dicts_of_tuples:\n",
    "            mydict[dicts[\"label\"]] = dicts[\"score\"]\n",
    "    return pd.Series(mydict)\n",
    "\n",
    "\n",
    "def add_sentiment_cols_hf(dataframe, text_col=\"text\"):\n",
    "    sentiment_cols = dataframe[text_col].apply(get_sentiment)\n",
    "    dataframe = pd.concat([dataframe, sentiment_cols], axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_data_hf(json_file):\n",
    "    pandas_df = pd.read_json(json_file)\n",
    "    filtered_df = pandas_df.loc[(pandas_df.loc[:, ~pandas_df.columns.isin(['url', 'page_title'])] != \"\").any(axis=1)] # exkludiert alle spalten von der Analyse die \"\" in den spalten ausser \"page_title\" haben \n",
    "    data = merge_columns_in_dataframe(filtered_df)\n",
    "    return add_sentiment_cols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>page_title</th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Selbstunfall mit dem Auto – was nun?</td>\n",
       "      <td>Selbstunfall mit dem Auto – was nun?  Selbst s...</td>\n",
       "      <td>0.785902</td>\n",
       "      <td>0.107085</td>\n",
       "      <td>0.107012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Invalidität oder Todesfall: So sorgen Sie vor</td>\n",
       "      <td>Invalidität oder Todesfall: So sorgen Sie vor ...</td>\n",
       "      <td>0.488104</td>\n",
       "      <td>0.375045</td>\n",
       "      <td>0.136852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Schäden an Ihrer Mietwohnung</td>\n",
       "      <td>Schäden an Ihrer Mietwohnung Für welche Schäde...</td>\n",
       "      <td>0.795895</td>\n",
       "      <td>0.108779</td>\n",
       "      <td>0.095326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "1  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "\n",
       "                                      page_title  \\\n",
       "1           Selbstunfall mit dem Auto – was nun?   \n",
       "2  Invalidität oder Todesfall: So sorgen Sie vor   \n",
       "3                   Schäden an Ihrer Mietwohnung   \n",
       "\n",
       "                                                text  negative  positive  \\\n",
       "1  Selbstunfall mit dem Auto – was nun?  Selbst s...  0.785902  0.107085   \n",
       "2  Invalidität oder Todesfall: So sorgen Sie vor ...  0.488104  0.375045   \n",
       "3  Schäden an Ihrer Mietwohnung Für welche Schäde...  0.795895  0.108779   \n",
       "\n",
       "    neutral  \n",
       "1  0.107012  \n",
       "2  0.136852  \n",
       "3  0.095326  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analysis_data_hf(\"hans.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>page_title</th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Selbstunfall mit dem Auto – was nun?</td>\n",
       "      <td>selbstunfall auto – ? schuld ! sekund aufgepas...</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5627</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Invalidität oder Todesfall: So sorgen Sie vor</td>\n",
       "      <td>invaliditat todesfall : sorg optimal vorsorg ,...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.mobiliar.ch/versicherungen-und-vor...</td>\n",
       "      <td>Schäden an Ihrer Mietwohnung</td>\n",
       "      <td>schad mietwohn schad haft mieterin miet ? freu...</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9749</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "1  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "2  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "3  https://www.mobiliar.ch/versicherungen-und-vor...   \n",
       "\n",
       "                                      page_title  \\\n",
       "1           Selbstunfall mit dem Auto – was nun?   \n",
       "2  Invalidität oder Todesfall: So sorgen Sie vor   \n",
       "3                   Schäden an Ihrer Mietwohnung   \n",
       "\n",
       "                                                text    neg    neu    pos  \\\n",
       "1  selbstunfall auto – ? schuld ! sekund aufgepas...  0.025  0.975  0.000   \n",
       "2  invaliditat todesfall : sorg optimal vorsorg ,...  0.000  0.963  0.037   \n",
       "3  schad mietwohn schad haft mieterin miet ? freu...  0.039  0.961  0.000   \n",
       "\n",
       "   compound judgement  \n",
       "1   -0.5627  negative  \n",
       "2    0.7820  positive  \n",
       "3   -0.9749  negative  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analysis_data(\"hans.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WBTH-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
